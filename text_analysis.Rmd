---
title: "Text Analysis"
author: "Jinyu Li"
date: "2021/12/06"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=F,message = F,echo=F,highlight=F)
#knitr::opts_chunk$set(echo = TRUE,out.width="0.9\\linewidth",dev="png",fig.align  = 'center')
knitr::opts_chunk$set(fig.width=5, fig.height=5,fig.align = "center") 
pacman::p_load(
tidyverse,
magrittr,
knitr,
gutenbergr,
tidytext,
sentimentr,
textdata
)



```

## Task 1: Pick a Book

The book I chose is written by Charlse Dickens, and the book name is "Hard Times" and shortened as "A Christmas Carol" because we are gonna spend our final time of the year at Christmas.

```{r}
# search the books from one author
# gutenberg_works(str_detect(author, "Dickens"))

# get the book from the website
Christmas_df = gutenberg_download(gutenberg_id = 46)

#my_books=hard_times_df

# save it into txt  
# write.table(Christmas_df,'A_Christmas_Carol.txt',row.names = F)

```

```{r}
library(tnum)
tnum.authorize("mssp1.bu.edu")
tnum.setSpace("test2")
source("Book2TN-v6A-1.R")

```




```{r}
# get the table from txt
Christmas_table <-read.table('A_Christmas_Carol.txt',header = T)

```

## TASK 2: Bag of Word Analysis

In this part, I will show the sentiment analysis by using AFINN, Bing and NRC respectively. I am going to plot several barplots to compare these 3 methods And show the differences of them.

The book, A Christmas Carol, is in general a book with more negative sentiments than positive sentiments. 

To briefly summarize the book, at the very beginning, the book describes the background of Ireland in the 1840s, where people were suffering from hungers and coldness. The leading character of the novel is Scrooge, who is a scrooge literally. He loves money and does not spare his mercy to others. On Christmas eve, so many ghosts visited Scrooge's house and made him see his death. After the night, Scrooge realized that money would be gone one day and changed himself and 

In conclusion, according to the plotline, the sentiment of the book should be negetive at first and positive at the very last, which I find Bing lexicon and Afinn lexicon both work well. It's hard to tell which one works the better. The only difference bewteen these 2 I find is that the sentiment by Bing lexicon is more negetive, which I think may fit the book better.

Consequently, in the following part, I will mainly do the sentiment analysis by using Bing lexicon.


```{r}
# generally display the book saved in dataframe
Christmas_table
```


```{r}
# Find the chapter for the book;
# Add one column to record the chapter number for each token

tidy_Christmas <- Christmas_table %>%
  mutate(
    linenumber = row_number(),
    chapter = cumsum(str_detect(text, 
                                regex("<")
                                      ))) %>%
  unnest_tokens(word, text)

#tidy_Christmas$chapter%>%unique()
#tidy_Christmas%>%view()
```


```{r}
afinn_Christmas_list <- tidy_Christmas %>% 
  inner_join(get_sentiments("afinn"))

bing_Chritmas_list <- tidy_Christmas %>% 
    inner_join(get_sentiments("bing")) %>%
    mutate(method = "Bing et al.")

nrc_Chritmas_list <- tidy_Christmas %>% 
    inner_join(get_sentiments("nrc") %>% 
                 filter(sentiment %in% c("positive", 
                                         "negative")))%>%
    mutate(method = "NRC")
```

```{r}
# 
afinn_Christmas <- tidy_Christmas %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(index = linenumber %/% 80) %>% 
  summarise(sentiment = sum(value)) %>% 
  mutate(method = "AFINN")

bing_and_nrc <- bind_rows(
  tidy_Christmas %>% 
    inner_join(get_sentiments("bing")) %>%
    mutate(method = "Bing et al."),
  tidy_Christmas %>% 
    inner_join(get_sentiments("nrc") %>% 
                 filter(sentiment %in% c("positive", 
                                         "negative"))
    ) %>%
    mutate(method = "NRC")) %>%
  count(method, index = linenumber %/% 80, sentiment) %>%
  pivot_wider(names_from = sentiment,
              values_from = n,
              values_fill = 0) %>% 
  mutate(sentiment = positive - negative)


afinn_Christmas_list



afinn_Christmas
df1 <- bing_and_nrc
df2 <- bind_rows(bing_Chritmas_list,nrc_Chritmas_list)%>%
  count(method, index = linenumber %/% 80, sentiment) %>%
  pivot_wider(names_from = sentiment,
              values_from = n,
              values_fill = 0) %>% 
  mutate(sentiment = positive - negative)
  
```

```{r fig.cap="sentiment plot for A Christmas Carol"}
#

bind_rows(afinn_Christmas, 
          bing_and_nrc) %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y")+
  theme_bw()
```


```{r}
bing_word_counts <- tidy_Christmas %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()
```

```{r fig.width=6, fig.height=2,fig.cap="negative positive words count"}
#
bing_word_counts %>%
  group_by(sentiment) %>%
  slice_max(n, n = 10) %>% 
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(x = "Contribution to sentiment",
       y = NULL)+
  theme_bw()
```

Figure 2 presents the top 10 negative and positive word count. In the negative barplot chart, the word  "poor" is the most common word followed by word "cold" and "dark". In the positive part, The most frequent word is "good" with "like" and "great" following after.


```{r fig.width=6, fig.height=4,fig.cap='word cloud'}
library(wordcloud)

tidy_Christmas %>%
  anti_join(stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100, colors = "brown2"))
```

Figure 3 displays word cloud which shows the frequency. As we can see, baron, mother, edgar are the most frequency words among all the words. It is reasonable because they are the main characters in that fiction book. In task 3, I will use two of three characters to conduct further analysis.


```{r fig.width=6, fig.height=4,fig.cap="sentiment word cloud"}
#
library(reshape2)

tidy_Christmas %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("brown2", "darkolivegreen3"),
                   max.words = 100, scale = c(4.6,0.2))
```

Figure 4 generally converts Figure 2's information into word cloud  

## task 3 sentence-level analysis

### tnum

First, I put the book into tnum, the following table shows evidence of my tnum database.

```{r, message=FALSE, warning=FALSE}
# tnBooksFromLines(Christmas_table$text, "Charlse_Dickens/A_Christmas_Carol_4")
# q20<-tnum.query(query="Charlse_Dickens/A_Christmas_Carol# has *",max=100000) %>% tnum.objectsToDf()
# df20 <- tnum.objectsToDf(q20)
# df20 %>% view()
```

```{r echo=TRUE, message=FALSE}
df_heading<- tnum.query('Charlse_Dickens/A_Christmas_Carol_4/heading# has text',max=90) %>% tnum.objectsToDf()
kable(df_heading %>% select(subject:numeric.value))
```


```{r echo=TRUE}
# q26<- tnum.query('*# has text',max=300000) %>% tnum.objectsToDf()
df_text <- tnum.query('Charlse_Dickens/A_Christmas_Carol_4# has text',max=60) %>% tnum.objectsToDf()
df_text %>% select(subject:string.value)%>% head()

```








```{r}

df_section<- tnum.query('Charlse_Dickens/A_Christmas_Carol_4/section# has text',max=9000) %>% tnum.objectsToDf()
#df27 %>% view()
Christmas_by_sentence<-df_section %>% separate(col=subject,
                  into = c("path1", "path2","section","paragraph","sentence"), 
                  sep = "/", 
                  fill = "right") %>% 
  select(section:string.value)

#book_sentence$section<-str_extract_all(book_sentence$section,"\\d+") %>% unlist() %>% as.numeric()
Christmas_by_sentence<-Christmas_by_sentence %>% mutate_at(c('section','paragraph','sentence'),~str_extract_all(.,"\\d+") %>% unlist() %>% as.numeric())


### change the name of sentence_out
sentence_out<-Christmas_by_sentence %>% mutate(sentence_split = get_sentences(string.value))%$%
    sentiment_by(sentence_split, list(section))

plot(sentence_out)

```

### Compare this analysis with the analysis you did in Task TWO

It is difficult to directly compare Sentimentr and Bing's score. Therefore, I apply `scale` function to keep two variable into the same criteria. Then I use ggplot to plot bar plot. From the Figure below, we can see that the trends, say positive and negetive direction, are mainly similar. But the exact number differs from two methods. Generally, sentimentr package is more optimictic than Bing method. 
```{r}
normalize<-function(x){
  re<-(x-min(x)) /(max(x)-min(x))
  return(re)
}

normalize_log<-function(x){
  re<-(log(x) /log(max(x)))
  return(re)
}
```

```{r fig.cap="sentiment comparison"}
bing_new<-tidy_Christmas %>% 
    inner_join(get_sentiments("bing")) %>%
    mutate(method = "Bing et al.") %>% 
    count(method, index = chapter, sentiment) %>%
  pivot_wider(names_from = sentiment,
              values_from = n,
              values_fill = 0) %>% 
  mutate(sentiment = positive - negative)



bing_new_Chritmas<-bing_new %>% mutate(bing_scale=rank(sentiment)) %>% select(method,index,bing_scale)
colnames(bing_new_Chritmas)[2]='section'

sentence_out<-sentence_out %>% mutate(sentimentr_scale=rank(ave_sentiment))


sentence_out_2method<-left_join(sentence_out,bing_new_Chritmas,by='section')%>% select(section,bing_scale,sentimentr_scale)
sentence_out_2method_plot<-sentence_out_2method %>% pivot_longer(cols=c('sentimentr_scale','bing_scale'),names_to = 'sentiment')

sentence_out_2method_plot %>%ggplot(aes(y=value,x=factor(section))) +
  geom_bar(aes(fill=factor(sentiment)),stat='identity',position = "dodge",width = 0.7)+theme_bw()

```

\newpage


### EXTRA CREDIT: Character Analysis

Baron and Edger are two main character among the fiction book. I Pick these two characters from my book.     
The following table in the count number of times each character appears in each chapter:

```{r}
#theme(legend.key.size = unit(2, 'cm'),legend.title = element_text(size=30),legend.text = element_text(size=30))
book_sentence_indi<-book_sentence %>% mutate(baron=str_match(book_sentence$string.value,regex('([Bb]aron)'))[,1],
                         edgar=str_match(book_sentence$string.value,regex('(Edgar)'))[,1])


score<-book_sentence_indi %>% dplyr::mutate(sentence_split = get_sentences(string.value))%$%
    sentiment_by(sentence_split) %>% `$`(ave_sentiment)

book_sentence_indi$score<-score
re<-book_sentence_indi %>% group_by(section) %>% summarise(baron=sum(baron %>% is.na() %>% `!`()),
                                                       edgar=sum(edgar%>% is.na() %>% `!`()))

#knitr::kable(re,'simple')
re2<-book_sentence_indi %>% group_by(section,paragraph) %>% summarise(
  both_appear=sum(baron %>% is.na() %>% `!`() & edgar%>% is.na() %>% `!`() ))

#re2 %>% filter(both_appear>0)
#knitr::kable(re2 %>% filter(both_appear>0),'simple')
```

chapter    baron   edgar
--------  ------  ------
       1      10       2
       2      22      17
       3      18      16
       4      13      12
       5       9       5
       6      16      18
       7      12      13
       8      15      24
       9      13      19
      10       8      14
      11      10      12
      12       5      18
      13       0      11
      14       1      13
      15       1      14




The following table is the count of number of times both characters appear in the same paragraphs.


 section   paragraph   both_appear
--------  ----------  ------------
       2           4             1
       2          28             1
       2          35             1
       2          36             1
       2          40             1
       3           1             1
       3          16             1
       4           3             1
       4           7             1
       4          11             1
       4          12             1
       4          23             1
       4          28             1
       5           1             1
       6           1             1
       6           3             1
       6          21             1
       7           5             1
       7           7             1
       7           8             1
       7           9             1
       8           1             1
       8           6             1
       8          11             1
       8          29             1
       8          31             1
       8          35             1
       9           2             1
       9          21             1
       9          32             1
       9          41             1
      10          11             1
      11           5             1
      11          16             2


```{r eval=F}


tnum.getDBPathList(taxonomy="subject", levels=2)

#tnBooksFromLines(time_machine$text, "wells/hw_time_1")

q20<-tnum.query(query="zweig/test1# has *",max=100000)
df20 <- tnum.objectsToDf(q20)
df20 %>% view()
q24<- tnum.query('zweig/test1/heading# has *',max=60)
df24 <- tnum.objectsToDf(q24)
df24 %>% view()

q26<- tnum.query('zweig/test1# has text',max=6000)
df26 <- tnum.objectsToDf(q26)
df26 %>% view()


# q24<- tnum.query('wells9/hw9/heading# has *',max=6000)
# df24 <- tnum.objectsToDf(q24)
# 
# q22<-tnum.query('wells9/hw9/heading:0022# has *')
# df22<-tnum.objectsToDf(q22)
# ord_ch1 <-unlist( tnum.query('wells9/hw9/heading:0022# has ordinal') )
# ord_ch2<-unlist(tnum.query('wells9/hw9/heading:0023# has ordinal'))
# 
# q25<-tnum.query('wells9/hw9/heading:0023# has *')
# df25<-tnum.objectsToDf(q25)
#   
# ch1_txt<-tnum.query('wells9/hw9/section:0022/paragraph:0002# has text',max=30)
# ch1_txt_df<-tnum.objectsToDf(ch1_txt)
# ch1_txt_df$string.value
# 
# ch2_txt<-tnum.query('wells9/hw9/section:0022/paragraph:0002/sentence:# has *',max=30)
# 
# ch2_txt_df<-tnum.objectsToDf(ch2_txt)
# ch2_txt_df$string.value
# 
# length(ch2_txt_df$string.value)
# 
# 
# q21<-tnum.query('wells9/hw9/section:0022/paragraph:0001/# has *',max=30)
# df21<-tnum.objectsToDf(q21)
# 
# library(sentimentr)
# 
# my_book$text[105:145] %>% sentiment()
```

